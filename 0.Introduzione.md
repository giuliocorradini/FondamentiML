# Introduzione

Il corso sarà diviso in due macrocategorie: ottimizzazione numerica e ottimizzazione stocastica.

Sotto l'assunzione che esista il gradiente di una funzione, si fa l'ottimizzazione numerica classica.
Una delle tecniche più utilizzate sono le _support vector machine_.

Quando la dimensione dei problemi aumenta, aumenta anche in modo significativo la difficoltà dei problemi
di ottimizzazione. A dimensioni elevate si sfruttano schemi di ottimizzazione stostatica, e anche qui siamo
sotto l'assunzione che

> è possibile calcolare il gradiente della funzione.

## Machine Learning

Vogliamo creare un algoritmo per automatizzare i processi di riconoscimento che noi umani compiamo
quotidianamente. Per farlo con una macchina dobbiamo rappresentare un fenomeno con un modello tramite cui fare
predizioni sul fenomeno.

## Framework matematico (osservare dei fenomeni)

Voglio avere delle informazioni sul fenomeno che sto osservando. Matematicamente si traduce in avere $n$ esempi
che possono essere a più dimensione.

In ambito di supervised ML, oltre alle informazioni di esempio utilizziamo anche delle _label_, ovvero informazioni
che descrivono l'esempio.

$$
D = \{(x_i, y_i), i=1, \dots, N, \space x_i \in \mathbb X, \space y_i \in \mathbb Y\}
$$

Gli esempi sono definiti come delle coppie. Il modello per fare predizioni è una funzione

$$
F : \mathbb X \to \mathbb Y
$$

detta predittore o funzione di decisione, che mi permette di associare punti dello spazio degli esempi  allo spazio
delle label.

### Terminologia del supervised learning

L'etichetta è un numero reale, in base ai valori cadiamo in categorie diversi. Se le label assumono valori $\{-1, 1\}$
allora il problema è di classificazione binaria.

Problemi di classificazione multi-class hanno una label che assume $l$ valori interi diversi. Ad esempio un classificatore per MNIST.

I problemi di regressione invece hanno la caratteristica di possedere una label reale.

### Unsupervised learning

Abbiamo gli esempi senza label, come per chi produce riconoscitori di banconote che non possono accedere sempre a
banconote false. Oppure chi deve riconoscere un alimento protetto da certificazione come il Parmigiano Reggiano, dove si
conosce bene cosa si sta cercando ma non si hanno a disposizione esempi della classe complementare.

Abbiamo i problemi di _novelty detection_ e di _clustering_. Filone di ML che non affronteremo.

### Collezionare esempi

Si collezionano esempi del dataset, diviso in tre partizioni (disgiunti!), si utilizza il training set per addestrare
il modello. Il validation set serve per validare il modello sugli esempi mentre il testing set serve per stimare le
performance del modello su questi esempi.

È importante anche la fase di processing del training set: ripulire i dati, isolare quelli interessanti e ridurre il rumore.
L'efficacia dello strumento di learning dipende enormemente dalla bontà del set.
